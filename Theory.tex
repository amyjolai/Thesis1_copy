\chapter{Theory and Implementation}
\label{chapterlabel2}
%The theoretical basis for methods used in this thesis and more widely in compuational chemistry is described in this chapter.

\section{Electronic structure methods}
%Intro to the history spiel. What it is, where did it come from. 
%Wave particle duality. 
% Dodgy first sentence, change it. 
Electronic structure methods apply the principles of quantum mechanics to the evaluation of electron position and movement, thereby allowing chemists to derive the properties and interactions of molecules. At the most fundamental level, the wavefunction ($\Psi$) holds the description of a quantum system. %Need a linking sentence here - What is the wavefunction, and why do we need to look at the probablility densiy instead?
In a non-relativistic system, the probability of a particle possessing a given momentum, or residing in a particular place, is given by the probability density. This can be obtained by  multiplication of $\Psi$ with its complex conjugate,  $|\Psi^{2}|$. %Born interpretation. Ref? 
Integration of $|\Psi^{2}|$ over a region of space returns the probability that a system will be found within.
%, such that the integral of over a region of space returns the probability that a system will be found within. %in that region.$|\Psi^{*}\Psi|$ 
%In Born's statistical interpretation in non-relativistic quantum mechanics,[8][9][10] the squared modulus of the wave function, |ψ|2, is a real number interpreted as the probability density of measuring a particle's being detected at a given place – or having a given momentum – at a given time, and possibly having definite values for discrete degrees of freedom. The integral of this quantity, over all the system's degrees of freedom, must be 1 in accordance with the probability interpretation. This general requirement that a wave function must satisfy is called the normalization condition. Since the wave function is complex valued, only its relative phase and relative magnitude can be measured—its value does not, in isolation, tell anything about the magnitudes or directions of measurable observables; one has to apply quantum operators, whose eigenvalues correspond to sets of possible results of measurements, to the wave function ψ and calculate the statistical distributions for measurable quantities.
%From Wikipedia: https://en.wikipedia.org/wiki/Wave_function
%Read the page, it's pretty good. 
Values of $\Psi$ are chosen to be othonormal; integrating $|\Psi^{2}|$ over all space gives the probability of 1:
\begin{equation}
\braket{\Psi_{i}|\Psi_{j}} = \delta_{ij}
\end{equation}
Where all electrons are represented by $i$ and $j$, and:
\begin{center}
$\delta_{ij}=0$ for $i\neq j$\\
$\delta_{ij}=1$ for $i=j$
\end{center}
%that has been normalised,
%Therefore, for $|\Psi^{2}|$ that has been normalised, the integral over all space is equal to 1, indicating that the probability of finding the system in the space is equal to 1.  %[REF] 
Operators acting on $\Psi$ yield the observable properties of the system. The operator returning the energy of the system is called the the Hamiltonian operator ($\mathbf{H}$).
Erwin Schr\"{o}dinger first proposed his equation for the description of the wavefunction of a quantum system in 1926 \cite{schrodinger1926}. The time-independent %Schr\"{o}dinger's 
equation is:
%Unless you know the long form... given in short-form: %(equation \ref{equ:schrodinger}). NB MAKE
%\subsection{The Schr\"{o}dinger Equation} time independent schrodingers
\begin{equation}
%\centering
\mathbf{H}\Psi=E\Psi
\label{equ:schrodinger}
\end{equation}
%where $\mathbf{H}$ is the Hamiltonian operator and $E$ is the energy ofm the system. $\mathbf{H}$ is called the eigenvalue, $\Psi$ the eigenfunction and $E$ is scalar. 
where the Hamiltonian operator $\mathbf{H}$ is an eigenvalue of %the eigenfunction, 
the wavefunction 
$\Psi$, and $E$ is a scalar denoting the energy of the system. 
%Perhaps straight away reduce it down to atomic units. ie. When working in \ac{au}, the general form of the Hamiltonian is given by: And delete the line later about it getting reduced to 1. 
The general form of the Hamiltonian is given by:
\begin{equation}
\mathbf{H}= - \sum \frac{\hbar^{2}}{2m_e}\nabla_i^{2} - \sum \frac{\hbar^{2}}{2m_k}\nabla_i^{2} - \sum_{i} \sum_{k} \frac{e^{2}Z_{k}}{r_{ik}} + \sum_{i<j} \frac{e^{2}}{r_{ij}} + \sum_{k<l} \frac{e^{2}Z_{k}Z_{l}}{r_{kl}}
\label{equ:hamiltonian}
\end{equation}
where all electrons are represented by $i$ and $j$, and all nuclei by $k$ and $l$. 
%$i \rightarrow j$ encompasses all electrons and $k \rightarrow l$ all nuclei. 
$\hbar$ %= \frac{h}{2\pi}$
is the reduced Planck's constant ($\hbar = \frac{h}{2\pi}$), $m_e$ is the mass of an electron, $m_k$ is the mass of the nucleus $k$, $e$ is the charge of an electron, $Z_k$ is the atomic number of $k$ and $r_{xy}$ is the distance between particles $x$ and $y$. When using \ac{au}, the electronic mass, charge and reduced Planck's constant are reduced to a value of 1. $\nabla^{2}$ refers to the Laplacian operator, which describes the divergence of the gradient of a field. % What does this really mean, in a practical sense? 
In Cartesian space, this is defined as the second derivative of the gradient in the three dimensions: % Does it refer to the change in electronic position, in this case? Do I even need to mention much about Laplacian?
\begin{equation}
\nabla_i^{2} = \frac{\partial^{2}}{\partial x_{i}^{2}} + \frac{\partial^{2}}{\partial y_{i}^{2}} + \frac{\partial^{2}}{\partial z_{i}^{2}}
\label{equ:laplace}
\end{equation}
The first and second terms of equation (\ref{equ:hamiltonian}) correspond to the kinetic energy of the electrons and the nuclei, respectively. Electron-nuclear attraction is described by the third term, followed by the interelectronic and internuclear repulsive terms. The three latter potential energy terms are described just as in classical mechanics. %appear the same as in classical mechanics. %analogous with classical mechanics.
% attractive and repulsive terms are% potential energy terms that are
% described as in classical mechanics. 
%coloumbic interactions
The kinetic energy terms are expressed as the eigenvalue of the kinetic energy operator ($\mathbf{T}$):
\begin{equation}
\mathbf{T}=-\frac{\hbar^{2}}{2m}\nabla^{2}
\label{equ:KE}
\end{equation}
The Hamiltonian %Equation \ref{equ:hamiltonian}
can therefore be written in terms of the kinetic energy and potential energy operators:
\begin{equation}
\mathbf{H} = \mathbf{T}_{e} + \mathbf{T}_{N} + \mathbf{V}_{e-N}+ \mathbf{V}_{e-e} + \mathbf{V}_{NN}
\label{equ:Htot}
\end{equation}
where the terms are as they were in equation \ref{equ:hamiltonian}. %, the first two terms denoting the kinetic energy of the electrons and nuclei, and the latter three terms detailing the electron-nuclear interactions.
%Was there really any point in rewriting it?
%The Hamiltonian for the full system is represented in terms of the kinetic energy and potential energy operators. 
%$\hat{H}$
%
%Dirac’s equations [REF] present the most complete description of a whole N-electron system by accounting fully for special relativity in the context of quantum mechanics, however many layers of approximation must be adopted in order to arrive at a model that is pliable within computational limitations. In the context of quantum electronic structure calculations it is usually appropriate to exclude the contribution of relativistic effects and nuclear motion, thus applying the Born-Oppenheimer approximation. 
%This presents the time independent Schrödinger’s equation \ref{equ:schrodinger}, which the Hartree-Fock approximation and many other electronic structure wavefunction based methods aim to solve. 
%
%The Hamiltonian operator (Eq. 3) acting on the wavefunction produces the electronic energy of a many electron system, where each of the terms in the Hamiltonian correspond to kinetic energies of the electrons and nuclei, the attraction of the electrons to the nuclei, and the inter-electronic and inter-nuclear repulsions.7
%

\subsection{Born-Oppenheimer approximation}
In a real system, the motion of elections and nuclei are coupled. Electron density flows dynamically in response to the change in nuclear position and repulsion from other electrons. The correlated motion of particles is described by the pairwise attractive and repulsive terms of the Schr\"{o}dinger’s equation. However, this interdependency results in a wavefuction that is difficult to define. 
%of such a system 
%this representation is unworkable owing to the complexity of considering the interdependent movement of all particles in the system. 
Relative to electronic motion, nuclei move far more slowly, owing to their mass. %The relaxation time of electrons may be treated as instantaneous, when comparing against that of the nuclei. 
%This difference in electronic and nuclear motion leads
The difference is such, that the nuclear positions appear essentially stationary compared to the electrons. Exploiting this property, the 
%Owing to this difference in relative  
Born-Oppenheimer approximation fixes the nuclear positions. In this way, the motion of electrons and nuclei can be decoupled, and the electronic properties of the system may be calculated for the given nuclear coordinates. The nuclear kinetic energy term ($\mathbf{T}_{N}$) of the Hamiltonian is removed, as the nuclei are frozen. % becomes then independent of electronic motion; 
%The electron-nuclear interaction term ($\mathbf{V}_{e-N}$) disappears, and 
The nuclear-nuclear repulsive term ($\mathbf{V}_{NN}$) becomes a constant.  
The equation is reduced to its electronic components and nuclear constants as:
%
%\begin{equation}
%\mathbf{H} = \mathbf{T}_{e} + \mathbf{V}_{e-N}+ \mathbf{V}_{e-e} + \mathbf{V}_{NN}
%\label{equ:BO}
%\end{equation}
% With AU:
\begin{equation}
\mathbf{H}= - \frac{1}{2} \sum \nabla_i^{2} - \sum_{i} \sum_{k} \frac{Z_{k}}{r_{ik}} + \sum_{i<j} \frac{1}{r_{ij}} + \mathbf{V}_{NN}
\label{equ:hamiltonian}
\end{equation}
%
The Schr\"{o}dinger’s equation only dependent on the electronic coordinates is as follows: 
%
\begin{equation}
(\mathbf{H}_{el} + \mathbf{V}_{NN})
\Psi_{el}(\mathbf{q}_{i};\mathbf{q}_{k})=E_{el}(\mathbf{q}_{i};\mathbf{q}_{k})
\label{equ:elec_schro}
\end{equation}
where $\mathbf{H}_{el}$ is the pure electronic Hamiltonian, that is, only including the electronic kinetic energy , electron-nucelar attractive term, and electron-electron repulsion term from the total Hamiltonian given in \ref{equ:hamiltonian}. $\mathbf{V}_{NN}$ is the nuclear-nuclear repulsion, constant for the fixed positions. %And so can be an additive term at the end. 
The electronic coordinates are given by $\mathbf{q}_{i}$, and the nuclear positions, $\mathbf{q}_{k}$.
$E_{el}$ is the electronic energy of the system, which is now only dependent on the electronic coordinates.
%
%\subsection{Slater determinant}
%In order to 
%
\subsection{Variational principle}
The variational theorem states that the calculated energy of any guess wavefunction can only be greater than or equal to the real ground-state energy of the system. % The concept of \''lower bound'' is a property of wavefunctions? How is this derived, and where does it stem from?
This provides a criterion for selection of the best guess wavefunction.


\subsection{Hartree Fock}
Hartree Fock \ac{HF} 
%Hartree Fock \nomenclature{HF}
%this might need to be shifted


\subsection{Open shell systems}
[PLEASE REVAMP ALL OF THIS AND FILL IN DETAIL]
The forced pairing of electrons of opposing spin into a shared orbital is referred to as the Restricted (RB3LYP) scheme. For systems without unpaired electrons, or “closed shell”, this treatment is sufficient. For radicals and other species with unpaired electron spin such as transition metal complexes, an alternative model allowing singly occupied orbitals must be adopted. The Restricted-Open (ROB3LYP) scheme maintains electron pairing within orbitals except in the case of the highest occupied molecular orbital (HOMO). This is singly occupied. An alternative model is Unrestricted (UB3LYP), where all electrons are unpaired and reside in their own orbitals (Figure 9). A caveat of the unrestricted model is its susceptibility to spin contamination, which has consequences at large bond separations where the bond has not completely broken.

\subsection{Electron correlation}

\subsection{Post-Hartree Fock methods}

\subsubsection{MP2}

\subsection{Density functional theory}
Solutions to the Schr\''{o}dinger's equation using reference

See here for a nice sum of the weaknesses: Some Fundamental Issues in Ground-State Density, Perdew 2009 (https://pubs.acs.org/doi/10.1021/ct800531s)
Functional Theory: A Guide for the Perplexed
[PLEASE REVAMP ALL OF THIS AND FILL IN DETAIL]\\
Density functional theory derives from the Thomas-Femi-Dirac model, whereby the electron correlation is modelled via functionals of the electron density.38,39 
The total energy is defined by functionals split into the following terms:
\[E=E^T+E^V+ E^J+ E^XC\] %if you remove this comment for some reason it goes italic

Where E$^{T}$ %ok, its the ^ that makes it go italic. 
is the kinetic energy term, arising from electron motion; E$^{V}$
is the potential energy term arising from nuclear-electron attraction and nuclear-nuclear repulsion; E$^{J}$ 
is the columbic repulsion term arising from electron-electron repulsion and E$^{XC}$  
is the exchange correlation term containing the remainder of the electron-electron interactions. The first three terms are purely classical, and correspond to the classical energy of the charge distribution ($\rho$).
The exchange term is non-classical encompasses the exchange energy due to the antisymmetry of the wavefunction, and dynamic correlation of electron motion. It can be further divided into the exchange and correlation components:
%$E\^XC (\rho)= E\^X (\rho)+ E\^C (\rhos)$
In the context of this report, the B3LYP functional will be used where the exchange is described as follows:
%\[E_B3LYP^XC= E_LDA^X+ c_0 (E_HF^X-E_LDA^X )+ c_X ∆E_B88^X+E_VWN3^C+c_C (E_LYP^C-E_VWN3^C )\]

Here c$_{0}$ = 0.2, c$_{X}$ = 0.72 and c$_{C}$ = 0.81.
The coefficient c$_{0}$ allows mixing of E$_{HF^X}$ (Hartree Fock) and E$_{LDA^X}$ (Local Density Approximation). E$_{VWN3^C}$ (VWN3 local correlation) is mixed with E$_{LYP^C}$ (Lee, Yang, Parr correlation function) via c$_{C}$. E$_{B88^X}$ is Becke’s gradient-corrected exchange functional.

{\textomega}B97x-d is a range separated hybrid with D (self consistent exchange). It is more computationally demanding than just post HF style perturbation theory exchange (as in B3LYP, using MP2 exchange for example  - fact check that). And according to the paper by Najibi and Goerigk even the D3 correction isn't better than the perturbation theory style exchange, for a massive amount of datasets that they tested. SO why even use this in the first place? Look to the origianl paper where it was published and see how they tout this method. Use those reasons to justify having chosen it to use on some of my systems. 

%remember to talk about the underestimation of the reaction barriers

\subsubsection{Hohenburg-Kohn formalism}
\subsubsection{Kohn-Sham Equations}
\subsubsection{Exchange-correlation functionals}
\ac{B3LYP}
\ac{wb97xd}
%Think this is the same as the above
%\subsection{Hybrid functionals}
\subsubsection{Dispersion correction}
Grimme
\subsection{Basis sets}
%make sure you know the caveats - ins and outs of the bases you used in combination with the methods you used. 
%You know pople's one's aren't as stable as the aug- ones. State why you chose them. Also, MP2 will react differently with these bases as opposed to the aug- ones. 
[FIX ME]
A basis set is the collection of mathematical basis functions used in linear combination to construct the molecular orbitals. Split valence basis sets describe the core electrons with fewer basis functions than the interacting valence electrons, as they are not as significant in bonding or intermolecular interactions. In this study, the widely used Pople basis sets will be applied (Table 1. Examples of split valence basis sets.).40,41 

Basis set superposition error (BSSE) is a false lowering of the energy that can occur when two species in a system approach one another to form a complex. Particle A borrows the extra basis functions belonging to particle B and an artificial stabilisation is observed. The error arises from the inconsistency in treatment between the individual particles at long separations and the complex at short distances. The effect is particularly pronounced for smaller basis sets. Counterpoise correction I used to circumvent BSSE, at the expense of higher computational resources required for the calculation.

\subsection{Thermochemistry}
(And vibrational frequencies)

\subsection{(Transition State Theory \& Free Energy Calculations)}

\subsection{Solvent models}
%Their effect on free energies - use a free energy cycle to justify the lack of inclusion of solvation energy - though this might be best discussed in Chap 1
%How they are modelled.
%PCM vs SMD, why is SMD better for free energies. Are they similar in terms of compuational demand

%\subsection{Optimisation algorithms}


\section{Analysis}

\subsection{Topology analysis using \ac{QTAIM}}

*paraphrase this:
Topology analysis Theory

Some real space functions in Multiwfn are available for topology analysis, such as electron density, its Laplacian, orbital wavefunction, ELF, LOL ...

The topology analysis technique proposed by Bader was firstly used for analyzing electron density in "atoms in molecules" (AIM) theory, which is also known as "the quantum theory of atoms in molecules" (QTAIM), this technique has also been extended to other real space functions, e.g. the first topology analysis research of ELF for small molecules is given by Silvi and Savin, see Nature, 371, 683. In topology analysis language, the points at where gradient norm of function value is zero (except at infinity) are called as critical points (CPs), CPs can be classified into four types according to how many eigenvalues of Hessian matrix of real space function are negative.

(3,-3): All three eigenvalues of Hessian matrix of function are negative, namely the local maximum. For electron density analysis and for heavy atoms, the position of (3,-3) are nearly identical to nuclear positions, hence (3,-3) is also called nuclear critical point (NCP). Generally the number of (3,-3) is equal to the number of atoms, only in rarely cases the former can be more than (e.g. Li2) or less than (e.g. KrH+) the latter.

(3,-1): Two eigenvalues of Hessian matrix of function are negative, namely the second-order saddle point. For electron density analysis, (3,-1) generally appears between attractive atom pairs and hence commonly called as bond critical point (BCP). The value of real space functions at BCP have great significance, for example the value of XXX and the sign of  at BCP are closely related to bonding strength and bonding type respectively in analogous bonding type (The Quantum Theory of Atoms in Molecules-From Solid State to DNA and Drug Design, p11); the potential energy density at BCP has been shown to be highly correlated with hydrogen bond energies (Chem. Phys. Lett., 285, 170); local information entropy at BCP is a good indicator of aromaticity (Phys. Chem. Chem. Phys., 12, 4742).

(3,+1): Only one eigenvalue of Hessian matrix of function is negative, namely first-order saddle point (like transition state in potential energy surface). For electron density analysis, (3,+1) generally appears in the center of ring system and displays steric effect, hence (3,+1) is often named as ring critical point (RCP).

(3,+3): None of eigenvalues of Hessian matrix of function are negative, namely the local minimum. For electron density analysis, (3,+3) generally appears in the center of cage system (e.g. pyramid P4 molecule), hence is often referred to as cage critical point (CCP).


(table \ref{tab:cps})

\begin{table}[htp]
\caption{Features of different types of critical point from \ac{QTAIM} topological analysis.}
\begin{center}
\begin{tabular}{l c p{4cm} p{3cm} p{3cm}} 
\toprule
Critical Point & Label  & Derivation & Attribute & Representation \\
\midrule
Nuclear (\acs{NCP}) & (3,-3)  & All 3 eivalues of the Hessian matrix are negative & Local maximum & Atomic nuclei \\
\hline
Bonding (\acs{BCP}) & (3,-1) & 2 negative eigenvalues of Hessian matrix  & 2\textsuperscript{nd} order saddle point & Bonding site \\
\hline
Ring (\acs{RCP}) & (3,+1) & 1 negative eigenvalue of Hessian matrix & 1\textsuperscript{st} order saddle point & Steric point or centre of ring system \\
\hline
Cage (\acs{CCP}) & (3,+3) & No negative eigenvalue of Hessian matrix& Local minimum & Centre of cage system \\
\bottomrule
\end{tabular}
\label{tab:cps}
\end{center}
\end{table}


The positions of CPs are searched by Newton method, one need to assign an initial guess point, then the Newton iteration always converge to the CP that is closest to the guess point. By assigning different guesses and doing iteration for each of them, all CPs could be found. Once searches of CPs are finished, one should use Poincaré-Hopf relationship to verify if all CPs may have been found, the relationship states that (for isolated system)

n(3,-3) – n(3,-1) + n(3,+1) – n(3,+3) = 1

If the relationship is unsatisfied, then some of CPs must be missing, you may need to try to search those CPs by different guesses. However even if the relationship is satisfied, it does not necessarily mean that all CPs have been found. Notice that the function spaces of ELF/LOL and Laplacian of XX are much more complex than XXX, it is very difficult to locate all CPs for these functions, especially for middle and large system, so, you can stop trying for searching CPs once all CPs that you are interested in have been found.

 

The maximal gradient path linking BCP and associated two local maxima of density is termed as “bond path”, which reveals atomic interaction path for all kinds of bonding. The collection of bond paths is known as molecular graph, which provides an unambiguous definition of molecular structure. Bond path can be straight line or curve, obviously for the latter case the length of bond path is longer than the sum of the distances between BCP and associated two (3,-3) CPs.

Let us see an example. In the complex shown below, the imidazole plane is vertical to magnesium porphyrin plane, the nitrogen in imidazole coordinated to magnesium. Magenta, orange and yellow spheres correspond to (3,-3), (3,-1) and (3,+1) critical points, brown lines denote bond paths.



\subsection{(Transition state searches)}
[Maybe this goes into a smaller metholodogy section?]
Transition state searches are called through the Opt=TS, QST or QST3 keywords. The Opt=TS method in GAUSSIAN attempts to optimise the given “guess” geometry to a transition state. The guess structure can be obtained from a geometry scan, manually constructed or generated using the QST2 function. In many cases, a TS alone will not be able to isolate the suitable transition state and is usually used in conjunction the QST2 or QST3 methods, and combined with other techniques such as frequency calculations. 
The QST2 option is able to generate a transition state geometry using the Synchronous Transit Quasi-Newton (STQN) method42. Here the transition geometry is midway between a given reactant and product. The corresponding atoms labels must match in both the starting and end products.  QST3 performs similarly, but also considers a guess transition state (Figure 10). It is widely acknowledged that transition state searching is challenging; in addition to the techniques above, the task requires perhaps a certain measure of chemical intuition.

`“Scan” means that the reaction coordinates are changed gradually and “relaxed” means that the reaction coordinates are fixed, while other coordinates that are orthogonal to the reaction coordinates are relaxed during the energy minimiza- tion` - Yao2018

%(within Gaussian? See if you end up using any)
Frequency calculations
\subsection{(Intrinsic Reaction Coordinate)}
[Maybe this goes into a smaller metholodogy section?]
IRC calculations begin at the saddle point and descend the PES in both the forwards and backwards direction of the reaction co-ordinate dictated by the normal mode of the imaginary frequency. In a similar manner to a geometry scan, geometry optimisations are performed at each step point. Its purpose is to connect the two minima leading to the found transition state, thereby confirming whether the found transition state corresponds to your reactants and products of interest. 
IRC calculations are called via the IRC keyword, with specifications of whether the forward or backward reaction is to be scanned, step size and maximum number of steps allowed.



%not sure whether to talk about the transistion state searching methods / algorithms here or elsewhere, or whether to go into detail at all.
\subsection{(PES Scans)}
[Maybe this goes into a smaller methodology section?]
Relaxed potential energy surface (PES) scans, or geometry scans are used to probe the local energy landscape corresponding to specific change in geometry. During the course of a scan, a selected bond length, angle or dihedral is adjusted in incremental steps, as specified by the given scan parameters. At each step, the adjusted parameter is frozen and a geometry optimisation is performed, allowing the rest of the system to relax around the modified bond.  Each scan yields a PES of the explored pathway, presented in a reaction co-ordinate diagram (see Figure 17, section 2.4.1).
An energy maximum followed by a trough indicates a transition state and intermediate reaction product, respectively. The structural co-ordinates at the points of interest are extracted and used for subsequent frequency calculations, transition state searches and validated using intrinsic reaction co-ordinate methods. 
To explore the predicted degradation mechanisms, the scanning parameter was assigned to the bond undergoing the most significant transformation during a particular step of the mechanism. In the case that more than one significant bond was altered, multiple scans with different bond specifications were compared. 
Geometry scans were performed on the optimised reactant geometry using the Opt=ModRedundant keyword.

A rigid scan consists of a single point energy calculation of the structure at each of step the scan. % change in coo-rdinates.
A relaxed scans calls for a geometry optmisation at each of these points. 
Two-dimensional scans may be used to probe simultaenous processes in thte system. These are specified in \ac{G09} by selecting two internal coordinates to be scanned, and stating the number of steps.




\section{Spectroscopy}

\subsection{Nuclear Magnetic Resonance Spectra}
Refer them to an actual resource, so you don't have to explain the theory of \ac{NMR}, but give an overview of the experimental, then give the theoretical detail about how Gaussian calculates it, and any discrepancies between experimental and calculated. 

Comment on the different methods used to calculate NMR parameters - a tiny literature review, if you will, and say which you'll be using, why - even if it's becuase of the fact that it's built into Gaussian (obviously big it up, if that is the case) - and state any caveats. 

Maybe have a look at: Accurate Calculation of NMR Chemical Shifts, Jurgen Gauss, 1995 as a basis, but you'll also need something more current. Any review papers out there?

\subsubsection{Computational implementation}

\subsection{Infra-Red Spectra}

%Update this later, looking at Tom's thesis, when you get round to actually doing some of the stuff
%\section{Molecular dynamics simulation methods}
Intro to the history spiel.

%Save this for the specific chapter?: \subsection{AMBER Forcefield}
% \section{Molecular mechanics}
% What are MM methods, e.g monte carlo

% \subsection{Interaction potentials}
% \subsubsection{Bonded terms}
% \subsubsection{Non-bonded terms}
% \subsubsection{Amber Force-field}
% Partial charges (?)
% Brief parameterisation spiel

% \subsection{Molecular Dynamics}
% verlet and leapfrog algorithms, thermostats and barostats
% \subsubsection{Ensembles}
% \subsubsection{Time integration algorithm}
% \subsubsection{Periodic boundary conditions}
% \subsubsection{Solvent models}
% \subsection{Optimisation algorithms}
% used in minimisations - used in Monte carlo, DFT as well
% \subsubsection{Steepest descent algorithm}
% \subsubsection{Conjugate gradient algorithm}

\subsubsection{Computational implementation}
Caveats and scaling factors. 





