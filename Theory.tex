\chapter{Theory and Implementation}
\label{chapterlabel2}
%References:
% Jensen
% Cramer
% Leach
%
%The theoretical basis for methods used in this thesis and more widely in computational chemistry is described in this chapter.
% include a physical constants page, with the numbers and roundings I used

% The rate at which you move through the topics is probably too slow. Can skip bits. They'll get it (although I'm not sure I will.)
\section{Electronic structure methods}
%Intro to the history spiel. What it is, where did it come from. 
%Wave particle duality. 
% Dodgy first sentence, change it. 
Electronic structure methods apply the principles of quantum mechanics to the evaluation of electron position and movement, thereby allowing chemists to derive the properties and interactions of molecules. At the most fundamental level, the wavefunction ($\Psi$) holds the description of a quantum system. %Need a linking sentence here - What is the wavefunction, and why do we need to look at the probablility densiy instead?
In a non-relativistic system, % So what happens in a relativistic system?
the probability of a particle possessing a given momentum, or residing in a particular location, is given by the probability density. This can be obtained by  multiplication of $\Psi$ with its complex conjugate,  $|\Psi^{2}|$. %Born interpretation. Ref? 
%Make sure you know what a complex conjugate is.
Integration of $|\Psi^{2}|$ over a region of space returns the probability that a system will be found within.
%, such that the integral of over a region of space returns the probability that a system will be found within. %in that region.$|\Psi^{*}\Psi|$ 
%In Born's statistical interpretation in non-relativistic quantum mechanics,[8][9][10] the squared modulus of the wave function, |ψ|2, is a real number interpreted as the probability density of measuring a particle's being detected at a given place – or having a given momentum – at a given time, and possibly having definite values for discrete degrees of freedom. The integral of this quantity, over all the system's degrees of freedom, must be 1 in accordance with the probability interpretation. This general requirement that a wave function must satisfy is called the normalization condition. Since the wave function is complex valued, only its relative phase and relative magnitude can be measured—its value does not, in isolation, tell anything about the magnitudes or directions of measurable observables; one has to apply quantum operators, whose eigenvalues correspond to sets of possible results of measurements, to the wave function ψ and calculate the statistical distributions for measurable quantities.
%From Wikipedia: https://en.wikipedia.org/wiki/Wave_function
%Read the page, it's pretty good. 
Values of $\Psi$ are chosen to be othonormal; % that is, orthogonal and normalised, such that integration of ...
integrating $|\Psi^{2}|$ over all space gives the probability of 1:
\begin{equation}
\braket{\Psi_{i}|\Psi_{j}} = \delta_{ij}
\end{equation}
%The above equation just means an integral of Psi_i and Psi_j over 3D Cartesian space. Or something to that effect.  
Where all states are represented by $i$ and $j$, and:
\begin{center}
$\delta_{ij}=0$ for $i\neq j$\\
$\delta_{ij}=1$ for $i=j$
%  δij is the Kronecker delta 
% Read Cramer page 107 for more clarfication
the integral is one.
\end{center}
%What does the delta refer to??
%Therefore, for $|\Psi^{2}|$ that has been normalised, the integral over all space is equal to 1, indicating that the probability of finding the system in the space is equal to 1.  %[REF] 
Operators acting on $\Psi$ yield the observable properties of the system. 
% How, and why?
The operator returning the energy of the system is called the the Hamiltonian operator ($\mathbf{H}$).
Erwin Schr\"{o}dinger %first 
proposed his equation in 1926, describing a quantum system using its wavefunction \cite{schrodinger1926}. %Check this is accurate. Does the equation use the wavefunction to describe the (energy of the) system, or does the equation just describe the wavefunction itself?
%The time-independent %Schr\"{o}dinger 
Schr\"{o}dinger's time independent equation is:
%Unless you know the long form... given in short-form: %(equation \ref{equ:schrodinger}). NB MAKE
%\subsection{The Schr\"{o}dinger Equation} time independent schrodingers
\begin{equation}
%\centering
\mathbf{H}\Psi=E\Psi
\label{equ:schrodinger}
\end{equation}
%where $\mathbf{H}$ is the Hamiltonian operator and $E$ is the energy ofm the system. $\mathbf{H}$ is called the eigenvalue, $\Psi$ the eigenfunction and $E$ is scalar. 
where the Hamiltonian operator $\mathbf{H}$ is an eigenvalue of %the eigenfunction, 
the wavefunction 
$\Psi$, and $E$ is a scalar denoting the energy of the system. 
A given system may have many acceptable values for $\Psi$, each with an associated value for $E$.
%(Cramer pg 107)

SEPARATION OF THE WAVEFUNCTION:\\
The $\Psi$ turns to $\psi$, and $\partial$ turns to d, after separation of terms. I don't really know why we changed the notation. But basically, once you start working with the time indepedent Schr, then switch to $\psi$, only. \\
[Note, time-\textbf{dependent} Schrodinger in one dimension ($x$), and time-independent potential energy for a single particle.]
The wavefunction evolves in time $\Psi(r_{1}, r_{2}....t)$  according to:
\begin{equation}
\textit{i}\hbar \frac{\partial \Psi}{\partial t} = H\Psi
\end{equation}

One dimension with time dependency:
\begin{equation}
H\Psi = - \frac{\hbar^{2}}{2m}\frac{\partial^{2} \Psi}{\partial x^{2}} + V(x)\Psi = \textit{i}\hbar \frac{\partial \Psi}{\partial t}
\end{equation}

Separation of variables:
\begin{equation}
\Psi(x,t) = \psi(x)\theta(t)
\end{equation}

Now:
\begin{equation}
 - \frac{\hbar^{2}}{2m}\theta \frac{d^{2} \psi}{d x^{2}} + V(x)\psi \theta = \textit{i}\hbar \psi \frac{d\theta}{dt}
\end{equation}

Simplifying by dividing by $\psi \theta$:
\begin{equation}
 - \frac{\hbar^{2}}{2m}\frac{1}{\psi} \frac{d^{2} \psi}{d x^{2}} + V(x)= \textit{i}\hbar \frac{1}{\theta} \frac{d\theta}{dt}
\end{equation}

%Perhaps straight away reduce it down to atomic units. ie. When working in \ac{au}, the general form of the Hamiltonian is given by: And delete the line later about it getting reduced to 1. 
%\textbackslash underbrace\{x+y\}\]\{|A|\
The general form of the Hamiltonian is given by 
\begin{equation}
\mathbf{H}= - \sum \frac{\hbar^{2}}{2m_e}\nabla_i^{2} - \sum \frac{\hbar^{2}}{2m_k}\nabla_k^{2} - \sum_{i} \sum_{k} \frac{e^{2}Z_{k}}{r_{ik}} + \sum_{i<j} \frac{e^{2}}{r_{ij}} + \sum_{k<l} \frac{e^{2}Z_{k}Z_{l}}{r_{kl}}
\label{equ:hamiltonian}
\end{equation}
where all electrons are represented by $i$ and $j$, and all nuclei by $k$ and $l$ \cite{Cramer2004}. 
%where electrons are labelled $i=1,2,3.....j$
%$i \rightarrow j$ encompasses all electrons and $k \rightarrow l$ all nuclei. 
$\hbar$ %= \frac{h}{2\pi}$
is the reduced Planck's constant ($\hbar = \frac{h}{2\pi} = 1.055\times10^{-34}$), 
$m_e$ is the mass of an electron, 
$m_k$ is the mass of the nucleus $k$, 
$e$ is the charge of an electron, 
%$\mathsf{e}$ is the charge of an electron %Change to sans serif, to differentiate from the exponential symbol? If so, change the equation too. 
$Z_k$ is the atomic number of $k$ and %$r_{xy}$ is the distance between particles $x$ and $y$.
$r_{ik}$ is the distance between particles $i$ and $k$. 
When using \ac{au}, %the electronic mass, charge and reduced Planck's constant 
the value of $e$, $m_e$ and $\hbar$ are reduced to 1. %Give the simplified equation here? %see Leah pg 29 for physical constants

$\nabla^{2}$ refers to the Laplacian operator, which describes the divergence of the gradient of a field. % It describes how the gradient (the gradient of a function of space) diverges over a function. Field or function? I guess if its a 3D plane function, you can call it a field.
%Laplacian of the electron density, is therefore the rate of change / divergence of the electron density, over that bit of space / cartesian coord?
% +ve is electron density deficient, -ve is electron density rich
%See the wiki: https://en.wikipedia.org/wiki/Laplace_operator
In Cartesian space, this is defined as the sum of the second derivatives of the gradient with respect to each of the three dimensions ($x$,$y$,$z$): % Does it refer to the change in electronic position, in this case? Do I even need to mention much about Laplacian?

\begin{equation}
\nabla_i^{2} = \frac{\partial^{2}}{\partial x_{i}^{2}} + \frac{\partial^{2}}{\partial y_{i}^{2}} + \frac{\partial^{2}}{\partial z_{i}^{2}}
\label{equ:laplace}
\end{equation}


%Maybe I should label the equation itself
The first and second terms of equation (\ref{equ:hamiltonian}) correspond to the kinetic energy of the electrons and the nuclei, respectively. Electron-nuclear attraction is described by the third term; %followed by the interelectronic and internuclear repulsive terms. 
the fourth term describes inter-electronic repulsion and the final term the inter-nuclear repulsion. 
The final three potential energy terms are identical to their expression in classical mechanics. %the same as in classical mechanics. 
%analogous with classical mechanics.
%identical to their expression / representation in classical mechanics. 
% attractive and repulsive terms are% potential energy terms that are
% described as in classical mechanics. 
%coloumbic interactions

%Probably don't need this section ----------------------------------------------------------------%
The kinetic energy terms %are 
can be expressed as the eigenvalue of the kinetic energy operator ($\mathbf{T}$):
\begin{equation}
\mathbf{T}=-\frac{\hbar^{2}}{2m}\nabla^{2}
\label{equ:KE}
\end{equation}

The Hamiltonian %Equation \ref{equ:hamiltonian}
can therefore be written in terms of the kinetic energy and potential energy operators:
\begin{equation}
\mathbf{H} = \mathbf{T}_{e} + \mathbf{T}_{N} + \mathbf{V}_{e-N}+ \mathbf{V}_{e-e} + \mathbf{V}_{NN}
\label{equ:Htot}
\end{equation}
where the terms are as they were in equation \ref{equ:hamiltonian}. %, the first two terms denoting the kinetic energy of the electrons and nuclei, and the latter three terms detailing the electron-nuclear interactions.
%Was there really any point in rewriting it?
%The Hamiltonian for the full system is represented in terms of the kinetic energy and potential energy operators. 
%$\hat{H}$
%
%Dirac’s equations [REF] present the most complete description of a whole N-electron system by accounting fully for special relativity in the context of quantum mechanics, however many layers of approximation must be adopted in order to arrive at a model that is pliable within computational limitations. In the context of quantum electronic structure calculations it is usually appropriate to exclude the contribution of relativistic effects and nuclear motion, thus applying the Born-Oppenheimer approximation. 
%This presents the time independent Schrödinger’s equation \ref{equ:schrodinger}, which the Hartree-Fock approximation and many other electronic structure wavefunction based methods aim to solve. 
%
%The Hamiltonian operator (Eq. 3) acting on the wavefunction produces the electronic energy of a many electron system, where each of the terms in the Hamiltonian correspond to kinetic energies of the electrons and nuclei, the attraction of the electrons to the nuclei, and the inter-electronic and inter-nuclear repulsions.7
%

%-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------%
\subsection{Born-Oppenheimer approximation}
%This maybe should be a paragraph rather than a whole multi-page section
%Get the original refrence - might be libo `s reference [27]
In a real system, the motion of elections and nuclei are coupled. Electron density flows dynamically in response to the change in nuclear position and repulsion from other electrons. The correlated motion of particles is described by the pairwise attractive and repulsive terms of the Schr\"{o}dinger equation. However, this interdependency makes defining a wavefunction difficult. 
% results in a wavefuction that is difficult to define. 
%of such a system 
%this representation is unworkable owing to the complexity of considering the interdependent movement of all particles in the system. 
Relative to electronic motion, nuclei move far more slowly, owing to their much greater mass (the mass of a proton is around 1836 times larger than that of the electron). %The relaxation time of electrons may be treated as instantaneous, when comparing against that of the nuclei. 
%This difference in electronic and nuclear motion leads
%The difference is such, that the 
Nuclear positions therefore appear essentially stationary when compared to that of the electrons. Exploiting this property, the 
%Owing to this difference in relative  
Born-Oppenheimer approximation fixes the nuclear positions. In this way, the motion of electrons and nuclei can be decoupled, and the electronic properties of the system may be calculated for the given nuclear coordinates. Dependency on the nuclear kinetic energy term ($\mathbf{T}_{N}$) of the Hamiltonian is removed, as the nuclei are frozen. % becomes then independent of electronic motion; 
%The electron-nuclear interaction term ($\mathbf{V}_{e-N}$) disappears, and 
The nuclear-nuclear repulsive term ($\mathbf{V}_{NN}$) becomes a constant for the specified geometry.  
Equation \ref{equ:hamiltonian} is reduced to its electronic components and nuclear constants which in atomic units can be written as:
%
%\begin{equation}
%\mathbf{H} = \mathbf{T}_{e} + \mathbf{V}_{e-N}+ \mathbf{V}_{e-e} + \mathbf{V}_{NN}
%\label{equ:BO}
%\end{equation}
% With AU:
\begin{equation}
\mathbf{H}= - \frac{1}{2} \sum \nabla_i^{2} - \sum_{i} \sum_{k} \frac{Z_{k}}{r_{ik}} + \sum_{i<j} \frac{1}{r_{ij}} + \mathbf{V}_{NN}
\label{equ:hamiltonian_BO}
\end{equation}
% Probably don't need this section ----------------------------------------------------------%
Or in terms of the operators:
\begin{equation}
\mathbf{H} = \mathbf{T}_{e} + \mathbf{V}_{e-N}+ \mathbf{V}_{e-e} + \mathbf{V}_{NN}
\label{equ:hamiltonian_BO_op}
\end{equation}
%
The electronic terms can be factorised into one term, to simplify notation:
\begin{equation}
\mathbf{H}= \mathbf{H}_{el}+ \mathbf{V}_{NN}
\label{equ:hamiltonian_BO_simp}
\end{equation}
%
The Schr\"{o}dinger’s equation can now be written in terms of only the electronic coordinates: 
%
\begin{equation}
(\mathbf{H}_{el} + \mathbf{V}_{NN})
\Psi_{el}(\mathbf{q}_{i};\mathbf{q}_{k})=E_{el}(\mathbf{q}_{i};\mathbf{q}_{k})
\label{equ:elec_schro}
\end{equation}
%where $\mathbf{H}_{el}$ is the pure electronic Hamiltonian, that is, only including the electronic kinetic energy , electron-nuclear attractive term, and electron-electron repulsion term from the total Hamiltonian given in \ref{equ:hamiltonian}. $\mathbf{V}_{NN}$ is the nuclear-nuclear repulsion, constant for the fixed positions. %And so can be an additive term at the end. 
where the electronic coordinates are given by $\mathbf{q}_{i}$, the stationary nuclear positions by $\mathbf{q}_{k}$ and 
$E_{el}$ is the electronic energy of the system. The values of $\mathbf{q}_{i}$ are independent variables, whereas the values of $\mathbf{q}_{k}$ are parameters. 
%significance of this?
% and thus appear following a semicolon rather than a comma in the variable list for \Psi
% so that the  Schr\"{o}dinger’s equation can be solved for the electrons alone. 

%CHECK this section
Given the example of a diatomic molecule, a potential energy curve can be obtained by calculating the value of $E_{el}$ for a particular inter-nuclear separation, increasing the separation distance and again calculating the energy. 
%(\ref{elements of physical chemistry})
A series of these calculations along different fixed nuclear separations generates a potential energy profile, allowing identification of an equilibrium bond length at the minimum of the curve. 
Calculation of $E_{el}$ for all possible nuclear coordinates allows the construction of the \ac{PES}	, a hypersurface on which nuclear motion occurs, with the potential energy defined by the nuclear geometry. % obtain transition structures for reaction involving a change in geometry, at the peak between two troughs.  

Molecular structure theories adopt the Born-Oppenheimer approximation for its effective simplification of the coupled nuclear-electronic motion problem, in addition to its relative accuracy; this assumption works well for ground state molecules and only introduces very small errors. %CHECK THIS, and what happens for excited ones?? / refs / examples
This model breaks down in the situation where there are multiple \ac{PES}, similar in energy %proximity 
to one another, or even intersecting. %CHECK / ref/ give examples
%See Jensen for clarification
In these cases the coupled equations must be considered. 
However for the work within this study, the Born-Oppenheimer approximation is successfully applied for all electronic structure calculations. 

%-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
\subsection{Slater determinants}
% A method of expressing the wavefunction, such that it obeys Pauli's
%Summed up as - antisymmetry and 
Equation \ref{equ:elec_schro} can be solved exactly in only a few circumstances; no exact solutions can be found for problems involving three or more interacting particles, such as in the case of a helium atom possessing two electrons and one proton. 

% A paragrah to talk about how exchange is the difficult bit to solve?
In a system of multiple electrons, each electron is indistinguishable. If the positions of two electrons is swapped, the distribution of electron density in the system remains the same. %\cite{Leach2001}. 
The Pauli exclusion principle states that no two identical fermions, such as electrons, may simultaneously occupy the same quantum state within the same system. When considering an atom with two or more electrons, this means that none may have an identical set of quantum numbers. %say what they are?
As a result, for two indistinguishable electrons, the wavefunction of the system is antisymmetric with respect to the exchange of their coordinates. 
%must therefore change sign upon the interchange of their coordinates
%permutation of their coordinates. %is this an imprecise statement?
%https://www.chem.tamu.edu/rgroup/hughbanks/courses/673/handouts/antisymmetry.pdf
\begin{equation}
\Psi(1,2..i,...j..N) = - \Psi(1,2..i,...j..N)
\end{equation}

%or
%\begin{equation}
%\Phi(\mathbf{X}_{1},\mathbf{X}_{2}) = - Phi(\mathbf{X}_{2},\mathbf{X}_{1})
%\end{equation} 

%These antisymmetry 
This requirement is fulfilled by expressing the wavefunction as a Slater determinant, which changes sign with permutation of the coordinates of two electrons. 
%What is a determinant anyway
In the case of a multi-electronic system, the generalised Slater determinant for $N$ total electrons is as follows: 

\begin{equation}
\psi_{SD} = \frac{1}{\sqrt{N!}}
\begin{vmatrix}
\chi_{1}(1) 	& \chi_{2}(1) 	&\cdots 	& \chi_{N}(1) \\
\chi_{1}(2) 	& \chi_{2}(2) 	&\cdots 	& \chi_{N}(2) \\
\vdots 		& \vdots 			& \ddots 	& \vdots 		   \\
\chi_{1}(N) & \chi_{2}(N) 	&\cdots 	& \chi_{N}(N) 
\end{vmatrix}
\end{equation}

where $\chi_{n}$ represents single electron wavefunctions, or spin-orbitals \cite{Slater1929}. %which are orthonormal
In the context of a molecule, the single electron wavefunctions are molecular orbitals. 
%Rows are labelled by the electrons: (1), (2) $\cdots$ ($N$), whereas columns are labelled by the orbitals: $\chi_{1}$, $\chi_{2} \cdots$, $\chi_{N}$.
%Rows are labelled by the coordinates of each electron: (1), (2) $\cdots$ ($N$)
Rows are labelled by the coordinates of each electron: $\textbf{x}_{1}$,$ \textbf{x}_{2}\cdots \textbf{x}_{N}$, whereas each column uses a different orbital function: $\chi_{1}$, $\chi_{2} \cdots$, $\chi_{N}$.
%The orbitals increase along the columns, whilst electron coordinates run down the rows. 
%If the labels of (1) and (2) are exchanged, the rows of the determinant are exchanged
If the labels of $\textbf{x}_{1}$ and $\textbf{x}_{2}$ are exchanged, the rows of the determinant are exchanged; a general property of determinants is that the interchange of two rows leads to a change of sign. The expanded form of the determinant ($\psi_{SD}$) will therefore have the opposite sign when when a pair of electron coordinates are switched, by switching rows within the determinant. 
In the disallowed case of two electrons occupying the same spin-orbital, two columns would be identical \cite{Dykstra1994}. The evaluation of the determinant would then be zero. 
Application of the Slater determinant therefore fulfils the Pauli exclusion principle. 

%-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
\subsection{Hartree Fock self-consistent field method}
%Need some preamble here, how did we get from slater and BO, to Hartree's method? 
%Not sure what this means, nor which they refer to:
% The product form of an electronic wavefunction is only obtainable \textit{via} and approximation. 
%The electronic Hamiltonian (equation \ref\label{equ:hamiltonian_BO_op}) is not separable for individual electrons. 
%This is prevented by the electron-electron repulsion term/ operator - an exact wavefunction cannot be determined as a product of the one electron function (from Slater's ?). 
%The electron-electron repulsion term 
The \ac{SCF} method was developed by Hartree 

 Hartree approximation neglects electron-electron interaction, describing the energy of electrons as individual particles without the effect of the surrounding fermions. 

Fock and Slater improved upon this by introducing electron exchange. This assumption places a static spherical potential around the electron, derived from the average effect of the nucleus and other electrons in the system. 

%Numerical solutions of the Schr\"{o}dinger equation present the best atomic orbitals \cite{Atkins2011} %Check this statement. 
The \ac{HF} method starts

\begin{equation}
E=\frac{\int\psi^{*}(\textbf{x}) H \psi(\textbf{x})d\textbf{x}}{\int\psi^{*}(\textbf{x}) \psi(\textbf{x})d\textbf{x}}
\label{equ:HF}
\end{equation}
%-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
\subsection{Variational principle}
%Expand on this later
The variational theorem states that the calculated energy of any guess wavefunction can only be greater than or equal to the real ground-state energy of the system. % The concept of \''lower bound'' is a property of wavefunctions? How is this derived, and where does it stem from?
This provides a criterion for selection of the best guess wavefunction, as the energy is always bound from below: 

%make sure you know what this means and whether the hat is appropriate
%\begin{equation}
%E_{exact} \leq {\langle \Psi | \hat{H} | \Psi \rangle}
%\end{equation}
\begin{equation}
E_{exact} \leq {\langle \Psi | \mathbf{H} | \Psi \rangle}
\end{equation}


%-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------%
\subsection{Open shell systems}
%[PLEASE REVAMP ALL OF THIS AND FILL IN DETAIL]
The forced pairing of electrons of opposing spin into a shared orbital is referred to as the Restricted scheme. %, (e.g. R\acs{B3LYP}).  You haven't describd functionals yet
For systems without unpaired electrons, or “closed shell”, this treatment is sufficient. For radicals and other species with unpaired electron spin such as transition metal complexes, an alternative model allowing singly occupied orbitals must be adopted. The Restricted-Open %e.g.RO\asc{B3LYP}, 
scheme maintains electron pairing within orbitals except in the case of the h\ac{HOMO}. This is singly occupied. An alternative model is Unrestricted, %(U\acs{B3LYP}), 
where all electrons are unpaired and reside in their own orbitals.% (Figure 9). 
A caveat of the unrestricted model is its susceptibility to spin contamination, which has consequences at large bond separations where the bond has not completely broken.

%\subsection{Electron correlation}
%
%\subsection{Post-Hartree Fock methods}
%
%\subsubsection{MP2}
%-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------%
\subsection{Density functional theory}
There are two approaches for solving the Schr\"{o}dinger equation for a polyatomic system with many electrons.  \textit{Ab initio} methods generate solutions from ``first principles'', where calculations are performed
By contrast, semi-epirical methods deal with parameters fitted to experimental quantities, such as enthalpies of formation or dipole moments. %ref if you can  
%Solutions to the Schrödinger equation using reference
%
%See here for a nice sum of the weaknesses: Some Fundamental Issues in Ground-State Density, Perdew 2009 (https://pubs.acs.org/doi/10.1021/ct800531s)
%Functional Theory: A Guide for the Perplexed
%[PLEASE REVAMP ALL OF THIS AND FILL IN DETAIL]\\
Density functional theory derives from the Thomas-Femi-Dirac model, whereby the electron correlation is modelled via functionals of the electron density.%38,39 
The total energy is defined by functionals split into the following terms:
\[E=E^T+E^V+ E^J+ E^XC\] %if you remove this comment for some reason it goes italic

Where E$^{T}$ %ok, its the ^ that makes it go italic. 
is the kinetic energy term, arising from electron motion; E$^{V}$
is the potential energy term arising from nuclear-electron attraction and nuclear-nuclear repulsion; E$^{J}$ 
is the columbic repulsion term arising from electron-electron repulsion and E$^{XC}$  
is the exchange correlation term containing the remainder of the electron-electron interactions. The first three terms are purely classical, and correspond to the classical energy of the charge distribution ($\rho$).
The exchange term is non-classical encompasses the exchange energy due to the antisymmetry of the wavefunction, and dynamic correlation of electron motion. It can be further divided into the exchange and correlation components:
\begin{equation}
\centering
E^{XC}(\rho) = E^{X}(\rho) + E^{C}(\rho)
\end{equation}

%\ac{wb97xd} is a range separated hybrid with D (self consistent exchange). 
%It is more computationally demanding than just post HF style perturbation theory exchange (as in B3LYP, using MP2 exchange for example  - fact check that). And according to the paper by Najibi and Goerigk even the D3 correction isn't better than the perturbation theory style exchange, for a massive amount of datasets that they tested. SO why even use this in the first place? Look to the origianl paper where it was published and see how they tout this method. Use those reasons to justify having chosen it to use on some of my systems. 

%remember to talk about the underestimation of the reaction barriers
%-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------%
%\subsubsection{Hohenburg-Kohn formalism}
%-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------%
%\subsubsection{Kohn-Sham Equations}%-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------%
%\subsubsection{Exchange-correlation functionals}
LDA, GGA etc and development of functionals. The different treatment of exchange. 
%-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------%
%%\subsection{Hybrid functionals}
%\subsubsection{Dispersion correction}
%Grimme
%-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------%
%\ac{B3LYP}

In the context of this report, the \ac{B3LYP} functional will be used where the exchange is described as follows:
\begin{equation}
\centering
E_{B3LYP^{XC}} = E_{LDA^{X}} + c_{0} (E_{HF^{X}}-E_{LDA^{X}} ) + c_{X} \Delta E_{B88^{X}} + E_{VWN3^{C}} + c_{C} (E_{LYP^{C}} -E_{VWN3^{C}} )
\end{equation}

Where c$_{0}$ = 0.2, c$_{X}$ = 0.72 and c$_{C}$ = 0.81.
The coefficient c$_{0}$ allows mixing of E$_{HF^{X}}$ (Hartree Fock) and E$_{LDA^{X}}$ (Local Density Approximation). E$_{VWN3^{C}}$ (VWN3 local correlation) is mixed with E$_{LYP^{C}}$ (Lee, Yang, Parr correlation function) via c$_{C}$. E$_{B88^{X}}$ is Becke’s gradient-corrected exchange functional.
%-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------%
%\ac{wb97xd}
%-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------%
\subsection{Basis sets}
%make sure you know the caveats - ins and outs of the bases you used in combination with the methods you used. 
%You know pople's one's aren't as stable as the aug- ones. State why you chose them. Also, MP2 will react differently with these bases as opposed to the aug- ones. 
%[FIX ME]
A basis set is the collection of mathematical basis functions used in linear combination to construct the molecular orbitals. Split valence basis sets describe the core electrons with fewer basis functions than the interacting valence electrons, as they are not as significant in bonding or intermolecular interactions. In this study, the widely used Pople basis sets will be applied. % (Table 1. Examples of split valence basis sets.).40,41 

%DO a mini test for this?

Basis set superposition error (BSSE) is a false lowering of the energy that can occur when two species in a system approach one another to form a complex. Particle A borrows the extra basis functions belonging to particle B and an artificial stabilisation is observed. The error arises from the inconsistency in treatment between the individual particles at long separations and the complex at short distances. The effect is particularly pronounced for smaller basis sets.% Counterpoise correction I used to circumvent BSSE, at the expense of higher computational resources required for the calculation.
%-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------%
%\subsection{Thermochemistry}
%(And vibrational frequencies)
%-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------%
%\subsection{(Transition State Theory \& Free Energy Calculations)}
%-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------%
%\subsection{Solvent models}
%%Their effect on free energies - use a free energy cycle to justify the lack of inclusion of solvation energy - though this might be best discussed in Chap 1
%%How they are modelled.
%%PCM vs SMD, why is SMD better for free energies. Are they similar in terms of compuational demand
%-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------%
%%\subsection{Optimisation algorithms}

%-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------%
\section{Implementation \& Analysis}
%
%Unless specified otherwies, all calcs run in G09 D.01 though perhaps make mention of materials studio, orca - no, Gview and Avogadro for quick cleanup. PyRed, what did I use to make the PBDs?
%Visualisation done in avogadro, molden, Gview
%
\subsection{Transition state searches}
%[Maybe this goes into a smaller metholodogy section?]
Transition state searches are called through the Opt=TS, QST or QST3 keywords. The Opt=TS method in \ac{G09} attempts to optimise the given “guess” geometry to a transition state. The guess structure can be obtained from a geometry scan, manually constructed or generated using the QST2 function. In many cases, a TS alone will not be able to isolate the suitable transition state and is usually used in conjunction the QST2 or QST3 methods, and combined with other techniques such as frequency calculations. 
The QST2 option is able to generate a transition state geometry using the Synchronous Transit Quasi-Newton (STQN) method42. Here the transition geometry is midway between a given reactant and product. The corresponding atoms labels must match in both the starting and end products.  QST3 performs similarly, but also considers a guess transition state. % (Figure 10). 
It is widely acknowledged that transition state searching is challenging; in addition to the techniques above, the task requires perhaps a certain measure of chemical intuition.
“Scan” means that the reaction coordinates are changed gradually and “relaxed” means that the reaction coordinates are fixed, while other coordinates that are orthogonal to the reaction coordinates are relaxed during the energy minimisation \cite{Yao2018}.

%(within Gaussian? See if you end up using any)
%Frequency calculations
\subsection{Intrinsic Reaction Coordinate}
%[Maybe this goes into a smaller metholodogy section?]
IRC calculations begin at the saddle point and descend the PES in both the forwards and backwards direction of the reaction co-ordinate dictated by the normal mode of the imaginary frequency. In a similar manner to a geometry scan, geometry optimisations are performed at each step point. Its purpose is to connect the two minima leading to the found transition state, thereby confirming whether the found transition state corresponds to your reactants and products of interest. 
IRC calculations are called via the IRC keyword, with specifications of whether the forward or backward reaction is to be scanned, step size and maximum number of steps allowed.

%not sure whether to talk about the transistion state searching methods / algorithms here or elsewhere, or whether to go into detail at all.
\subsection{PES Scans}
%[Maybe this goes into a smaller methodology section?]
Relaxed potential energy surface (PES) scans, or geometry scans are used to probe the local energy landscape corresponding to specific change in geometry. During the course of a scan, a selected bond length, angle or dihedral is adjusted in incremental steps, as specified by the given scan parameters. At each step, the adjusted parameter is frozen and a geometry optimisation is performed, allowing the rest of the system to relax around the modified bond.  Each scan yields a PES of the explored pathway, presented in a reaction co-ordinate diagram. % (see Figure 17, section 2.4.1).
An energy maximum followed by a trough indicates a transition state and intermediate reaction product, respectively. The structural co-ordinates at the points of interest are extracted and used for subsequent frequency calculations, transition state searches and validated using intrinsic reaction co-ordinate methods. 
To explore the predicted degradation mechanisms, the scanning parameter was assigned to the bond undergoing the most significant transformation during a particular step of the mechanism. In the case that more than one significant bond was altered, multiple scans with different bond specifications were compared. 
Geometry scans were performed on the optimised reactant geometry using the Opt=ModRedundant keyword.

A rigid scan consists of a single point energy calculation of the structure at each of step the scan. % change in coo-rdinates.
A relaxed scans calls for a geometry optimisation at each of these points. 
Two-dimensional scans may be used to probe simultaneous processes in the system. These are specified in \ac{G09} by selecting two internal coordinates to be scanned, and stating the number of steps.
%-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
\subsection{Topology analysis using \ac{QTAIM}}
%Some real space functions in Multiwfn are available for topology analysis, such as electron density, its Laplacian, orbital wavefunction, ELF, LOL ...
Topology analysis is a method of obtaining useful properties from the 3D representation of ...%the electron density derived during a quantum mechanical calculation. 
Bader proposed a technique to analyse the electron density in the \ac{QTAIM} \cite{Bader1991}.
 %, which also extended to other real space functions, such as the \ac{LOL} and \ac{ELF}. - Only include these if you can describe them, also. 
 % Real-space calculation...when all operators (T^,V^,J^,K^) are evaluated on a grid.
 %
%The topology analysis technique proposed by Bader was firstly used for analysing electron density in "atoms in molecules" (AIM) theory, which is also known as "the quantum theory of atoms in molecules" (QTAIM), this technique has also been extended to other real space functions, e.g. the first topology analysis research of ELF for small molecules is given by Silvi and Savin.%, see Nature, 371, 683. 
The points in the topological landscape at which the gradient norm is zero, excluding points at infinity, %does infinity happen?
% wiki: a norm is a function that assigns a strictly positive length or size to each vector in a vector space—except for the zero vector, which is assigned a length of zero.
% A bit like modulus but referers to specific scenarios: https://www.physicsforums.com/threads/what-is-the-difference-between-norm-and-modulus.181812/
signify a stationary point. These are deemed Critical Points (\acs{CP}).  In the context of electron density, these point can be classified into four types:
%In topology analysis language, the points at where gradient norm of function value is zero (except at infinity) are called as critical points (CPs), CPs can be classified into four types according to how many eigenvalues of Hessian matrix of real space function are negative.

%At this point you shoudl have already explained what the hessian matrix is
%please explaint the (3,X) labelling
\ac{NCP}: All three eigenvalues of Hessian matrix of the function are negative, also known as the local maximum. %For electron density analysis and for heavy atoms, the position of (3,-3) are nearly identical to nuclear positions, hence (3,-3) is also called nuclear critical point (NCP). Generally the number of (3,-3) is equal to the number of atoms, only in rarely cases the former can be more than (e.g. Li2) or less than (e.g. KrH+) the latter.
As the position of (3,-3) are generally located at nuclear positions, these are referred to as Nuclear Critical Points (\acs{NCP}). The number of \ac{NCP} is usually equal to the number of atoms, though there are exceptions, such as a greater number of \ac{NCP} for \ce{Li2} or a lower number for \ce{KrH+}. %Why???

%Btw real space.... just means space. As in actual 3D space. Not virtual space. 
%In a electronic structure (specifically DFT) code, a "real space code" means using atom orbitals as basis functions rather than plane waves.
% https://chemistry.stackexchange.com/questions/84098/what-are-the-differences-between-the-hilbert-space-and-real-space-representation
(3,-1): Two eigenvalues of Hessian matrix of function are negative, or a second-order saddle point. (3,-1) usually appears between attractive atom pairs and so are referred to as a Bonding Critical Points (\acs{BCP}). %The value of real space functions at BCP have great significance. %, for example the value of XXX and 
As the electron density af 
 \ac{BCP} is closely related to bonding strength and bonding type respectively in analogous bonding type. % (The Quantum Theory of Atoms in Molecules-From Solid State to DNA and Drug Design, p11); 
\cite{Matta2007}
The potential energy density at BCP has been shown to be highly correlated with hydrogen bond energies% (Chem. Phys. Lett., 285, 170)
; local information entropy at BCP is a good indicator of aromaticity.% (Phys. Chem. Chem. Phys., 12, 4742).

(3,+1): Only one eigenvalue of Hessian matrix of function is negative, namely first-order saddle point (like transition state in potential energy surface). For electron density analysis, (3,+1) generally appears in the center of ring system and displays steric effect, hence (3,+1) is often named as ring critical point (RCP).

(3,+3): None of eigenvalues of Hessian matrix of function are negative, namely the local minimum. For electron density analysis, (3,+3) generally appears in the center of cage system (e.g. pyramid P4 molecule), hence is often referred to as cage critical point (CCP).
%
%(table \ref{tab:cps})

\begin{table}[htp]
\caption{Features of different types of critical point from \ac{QTAIM} topological analysis.}
\begin{center}
\begin{tabular}{l c p{4cm} p{3cm} p{3cm}} 
\toprule
Critical Point & Label  & Derivation & Attribute & Representation \\
\midrule
Nuclear (\acs{NCP}) & (3,-3)  & 3 eigenvalues of Hessian matrix are -ve & Local maximum & Atomic nuclei \\
\hline
Bonding (\acs{BCP}) & (3,-1) & 2 eigenvalues of Hessian matrix are -ve & 2\textsuperscript{nd} order saddle point & Bonding site \\
\hline
Ring (\acs{RCP}) & (3,+1) & 1 eigenvalue of Hessian matrix is -ve & 1\textsuperscript{st} order saddle point & Steric point or centre of ring system \\
\hline
Cage (\acs{CCP}) & (3,+3) & No negative eigenvalue of Hessian matrix& Local minimum & Centre of cage system \\
\bottomrule
\end{tabular}
\label{tab:cps}
\end{center}
\end{table}

The positions of CPs are searched by Newton method, one need to assign an initial guess point, then the Newton iteration always converge to the CP that is closest to the guess point. By assigning different guesses and doing iteration for each of them, all CPs could be found. Once searches of CPs are finished, one should use Poincaré-Hopf relationship to verify if all CPs may have been found, the relationship states that (for isolated system)
\begin{equation}
\centering
n(3,-3) – n(3,-1) + n(3,+1) – n(3,+3) = 1
\end{equation}
%If the relationship is unsatisfied, then some of CPs must be missing, you may need to try to search those CPs by different guesses. However even if the relationship is satisfied, it does not necessarily mean that all CPs have been found. Notice that the function spaces of ELF/LOL and Laplacian of XX are much more complex than XXX, it is very difficult to locate all CPs for these functions, especially for middle and large system, so, you can stop trying for searching CPs once all CPs that you are interested in have been found.

 The maximal gradient path linking BCP and associated two local maxima of density is termed as “bond path”, which reveals atomic interaction path for all kinds of bonding. The collection of bond paths is known as molecular graph, which provides an unambiguous definition of molecular structure. Bond path can be straight line or curve, obviously for the latter case the length of bond path is longer than the sum of the distances between BCP and associated two (3,-3) CPs.
%Let us see an example. In the complex shown below, the imidazole plane is vertical to magnesium porphyrin plane, the nitrogen in imidazole coordinated to magnesium. Magenta, orange and yellow spheres correspond to (3,-3), (3,-1) and (3,+1) critical points, brown lines denote bond paths.
%-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
%\section{Spectroscopy}
%
%\subsection{Nuclear Magnetic Resonance Spectra}
%Refer them to an actual resource, so you don't have to explain the theory of \ac{NMR}, but give an overview of the experimental, then give the theoretical detail about how Gaussian calculates it, and any discrepancies between experimental and calculated. 
%
%Comment on the different methods used to calculate NMR parameters - a tiny literature review, if you will, and say which you'll be using, why - even if it's becuase of the fact that it's built into Gaussian (obviously big it up, if that is the case) - and state any caveats. 
%
%Maybe have a look at: Accurate Calculation of NMR Chemical Shifts, Jurgen Gauss, 1995 as a basis, but you'll also need something more current. Any review papers out there?
%-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------%
%\subsection{Infra-Red spectra}
% Already covered in the thermochemistry section? Maybe just refer to that, but the include the scaling factors in here
%\subsection{Nuclear Magnetic Resonance spectra}
%-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
%%Update this later, looking at Tom's thesis, when you get round to actually doing some of the stuff
%%\section{Molecular dynamics simulation methods}
%Intro to the history spiel.


%Save this for the specific chapter?: \subsection{AMBER Forcefield}
% \section{Molecular mechanics}
% What are MM methods, e.g monte carlo

% \subsection{Interaction potentials}
% \subsubsection{Bonded terms}
% \subsubsection{Non-bonded terms}
% \subsubsection{Amber Force-field}
% Partial charges (?)
% Brief parameterisation spiel

% \subsection{Molecular Dynamics}
% verlet and leapfrog algorithms, thermostats and barostats
% \subsubsection{Ensembles}
% \subsubsection{Time integration algorithm}
% \subsubsection{Periodic boundary conditions}
% \subsubsection{Solvent models}
% \subsection{Optimisation algorithms}
% used in minimisations - used in Monte carlo, DFT as well
% \subsubsection{Steepest descent algorithm}
% \subsubsection{Conjugate gradient algorithm}
%-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------%
%\subsubsection{Computational implementation}
%Caveats and scaling factors. 
% Computational chemistry now forms a fundamental part of chemical research either in conjunction with laboratory experimentation or independently. 






